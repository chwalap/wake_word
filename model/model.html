
<html>
<head>
<style>
body {font-family: sans-serif; background-color: #fa0;}
table {background-color: #eca;}
th {background-color: black; color: white;}
h1 {
  background-color: ffaa00;
  padding:5px;
  color: black;
}

svg {
  margin: 10px;
  border: 2px;
  border-style: solid;
  border-color: black;
  background: white;
}

div {
  border-radius: 5px;
  background-color: #fec;
  padding:5px;
  margin:5px;
}

.tooltip {color: blue;}
.tooltip .tooltipcontent  {
    visibility: hidden;
    color: black;
    background-color: yellow;
    padding: 5px;
    border-radius: 4px;
    position: absolute;
    z-index: 1;
}
.tooltip:hover .tooltipcontent {
    visibility: visible;
}

.edges line {
  stroke: #333;
}

text {
  font-weight: bold;
}

.nodes text {
  color: black;
  pointer-events: none;
  font-family: sans-serif;
  font-size: 11px;
}
</style>

<script src="https://d3js.org/d3.v4.min.js"></script>

</head>
<body>
<h1>TensorFlow Lite Model</h2><table>
<tr><th>filename</th><td>model.tflite</td></tr>
<tr><th>version</th><td>3</td></tr>
<tr><th>description</th><td>[77, 76, 73, 82, 32, 67, 111, 110, 118, 101, 114, 116, 101, 100, 46]</td></tr>
</table>
<div class='subgraph'><h2>Subgraph 0</h2>
<h3>Inputs/Outputs</h3>
<table><tr>
<tr>
<th>inputs</th><th>outputs</th></tr>
<tr>
<td><span class='tooltip'><span class='tooltipcontent'>0 serving_default_conv2d_1_input:0 FLOAT32 [1, 99, 43, 1][-1, 99, 43, 1]<br></span>[0]</span></td>
<td><span class='tooltip'><span class='tooltipcontent'>19 StatefulPartitionedCall:0 FLOAT32 [1, 1][-1, 1]<br></span>[19]</span></td>
</tr>
</table>
<h3>Tensors</h3>
<table><tr>
<tr>
<th>index</th><th>name</th><th>type</th><th>shape</th><th>shape_signature</th><th>buffer</th><th>quantization</th></tr>
<tr>
<td>0</td><td>serving_default_conv2d_1_input:0</td>
<td>FLOAT32</td>
<td>[1, 99, 43, 1]</td>
<td>[-1, 99, 43, 1]</td>
<td>1</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': None, 'zero_point': None}</td>
</tr>
<tr>
<td>1</td><td>wake_word/quant_flatten_5/Const</td>
<td>INT32</td>
<td>[2]</td>
<td>None</td>
<td>2</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': None, 'zero_point': None}</td>
</tr>
<tr>
<td>2</td><td>wake_word/quant_conv2d_1/BiasAdd/ReadVariableOp</td>
<td>INT32</td>
<td>[32]</td>
<td>None</td>
<td>3</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': [0.000404138962039724, 0.0002619295264594257, 0.0003772165218833834, 0.0004405086801853031, 0.0003289619053248316, 0.00048018735833466053, 0.00037750357296317816, 0.00034407226485200226, 0.00020757621678058058, 0.0007043480291031301, 0.0004449339467100799, 0.0004421118937898427, 0.00026027322746813297, 0.0005288474494591355, 0.00024899677373468876, 0.0003074189880862832, 0.0006398193654604256, 0.0004226373275741935, 0.0005052508204244077, 0.0004812404222320765, 0.0007871100679039955, 0.0001866624952526763, 0.0004338902363087982, 0.000602113374043256, 0.0005184635519981384, 0.0005428498843684793, 0.0005154907703399658, 0.0007121734670363367, 0.0003792047791648656, 0.0006655018078163266, 0.0004799180605914444, 0.0003570399130694568], 'zero_point': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}</td>
</tr>
<tr>
<td>3</td><td>wake_word/quant_conv2d_2/BiasAdd/ReadVariableOp</td>
<td>INT32</td>
<td>[32]</td>
<td>None</td>
<td>4</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': [0.0006947694928385317, 0.0006251064478419721, 0.0004751179658342153, 0.0005556035903282464, 0.0008163601742126048, 0.000498109613545239, 0.0005157249397598207, 0.000533970189280808, 0.0005564755410887301, 0.0005951310158707201, 0.0010640108957886696, 0.00065398751758039, 0.0006794460932724178, 0.0006260466179810464, 0.0004942338564433157, 0.0009018034907057881, 0.0005310446722432971, 0.00045773416059091687, 0.0005967447650618851, 0.0007154613267630339, 0.0004903498338535428, 0.0008337923791259527, 0.0007601897232234478, 0.0005101359565742314, 0.0007663621800020337, 0.0007513086893595755, 0.000509503879584372, 0.0005215510609559715, 0.0009003216400742531, 0.0011071834014728665, 0.0007710537174716592, 0.0009876842377707362], 'zero_point': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}</td>
</tr>
<tr>
<td>4</td><td>wake_word/quant_output/BiasAdd/ReadVariableOp</td>
<td>INT32</td>
<td>[1]</td>
<td>None</td>
<td>5</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': [0.0012407334288582206], 'zero_point': [0]}</td>
</tr>
<tr>
<td>5</td><td>wake_word/quant_dense_1/BiasAdd/ReadVariableOp</td>
<td>INT32</td>
<td>[32]</td>
<td>None</td>
<td>6</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': [0.0012121995678171515], 'zero_point': [0]}</td>
</tr>
<tr>
<td>6</td><td>wake_word/quantize_layer_2/AllValuesQuantize/FakeQuantWithMinMaxVars;wake_word/quantize_layer_2/AllValuesQuantize/FakeQuantWithMinMaxVars/ReadVariableOp;wake_word/quantize_layer_2/AllValuesQuantize/FakeQuantWithMinMaxVars/ReadVariableOp_1</td>
<td>INT8</td>
<td>[1, 99, 43, 1]</td>
<td>[-1, 99, 43, 1]</td>
<td>7</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': [0.17620722949504852], 'zero_point': [77]}</td>
</tr>
<tr>
<td>7</td><td>wake_word/quant_conv2d_1/Conv2D;wake_word/quant_conv2d_1/LastValueQuant/FakeQuantWithMinMaxVarsPerChannel</td>
<td>INT8</td>
<td>[32, 5, 5, 1]</td>
<td>None</td>
<td>8</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': [0.0022935436572879553, 0.0014864855911582708, 0.0021407550666481256, 0.002499946625903249, 0.0018669035052880645, 0.002725128550082445, 0.002142383949831128, 0.001952656893990934, 0.0011780232889577746, 0.0039972709491848946, 0.0025250606704503298, 0.0025090451817959547, 0.0014770859852433205, 0.0030012810602784157, 0.0014130905037745833, 0.0017446445999667048, 0.003631061874330044, 0.0023985242005437613, 0.0028673671185970306, 0.0027311048470437527, 0.004466956481337547, 0.0010593350743874907, 0.002462386153638363, 0.0034170751459896564, 0.002942351158708334, 0.0030807468574494123, 0.0029254802502691746, 0.004041681066155434, 0.0021520385053008795, 0.0037768131587654352, 0.002723600249737501, 0.002026250120252371], 'zero_point': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}</td>
</tr>
<tr>
<td>8</td><td>wake_word/quant_conv2d_1/Relu;wake_word/quant_conv2d_1/BiasAdd;wake_word/quant_conv2d_2/Conv2D;wake_word/quant_conv2d_1/Conv2D;wake_word/quant_conv2d_1/BiasAdd/ReadVariableOp</td>
<td>INT8</td>
<td>[1, 99, 43, 32]</td>
<td>[-1, 99, 43, 32]</td>
<td>9</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': [0.1398019641637802], 'zero_point': [-114]}</td>
</tr>
<tr>
<td>9</td><td>wake_word/quant_pool2d_1/MaxPool</td>
<td>INT8</td>
<td>[1, 33, 15, 32]</td>
<td>[-1, 33, 15, 32]</td>
<td>10</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': [0.1398019641637802], 'zero_point': [-114]}</td>
</tr>
<tr>
<td>10</td><td>wake_word/quant_conv2d_2/Conv2D;wake_word/quant_conv2d_2/LastValueQuant/FakeQuantWithMinMaxVarsPerChannel</td>
<td>INT8</td>
<td>[32, 3, 3, 32]</td>
<td>None</td>
<td>11</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': [0.0049696690402925014, 0.004471370950341225, 0.003398507134988904, 0.003974218852818012, 0.005839404184371233, 0.003562965663149953, 0.0036889680195599794, 0.0038194754160940647, 0.003980455920100212, 0.0042569576762616634, 0.007610843982547522, 0.004677956458181143, 0.0048600612208247185, 0.004478096030652523, 0.0035352427512407303, 0.006450578570365906, 0.0037985495291650295, 0.0032741613686084747, 0.004268500953912735, 0.00511767715215683, 0.0035074602346867323, 0.005964096635580063, 0.005437618587166071, 0.0036489900667220354, 0.005481769796460867, 0.005374092608690262, 0.003644468728452921, 0.003730642143636942, 0.00643997872248292, 0.007919656112790108, 0.005515328608453274, 0.007064880803227425], 'zero_point': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}</td>
</tr>
<tr>
<td>11</td><td>wake_word/quant_conv2d_2/Relu;wake_word/quant_conv2d_2/BiasAdd;wake_word/quant_conv2d_2/Conv2D;wake_word/quant_conv2d_2/BiasAdd/ReadVariableOp</td>
<td>INT8</td>
<td>[1, 33, 15, 32]</td>
<td>[-1, 33, 15, 32]</td>
<td>12</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': [0.18150728940963745], 'zero_point': [-117]}</td>
</tr>
<tr>
<td>12</td><td>wake_word/quant_pool2d_2/MaxPool</td>
<td>INT8</td>
<td>[1, 11, 5, 32]</td>
<td>[-1, 11, 5, 32]</td>
<td>13</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': [0.18150728940963745], 'zero_point': [-117]}</td>
</tr>
<tr>
<td>13</td><td>wake_word/quant_flatten_5/Reshape</td>
<td>INT8</td>
<td>[1, 1760]</td>
<td>[-1, 1760]</td>
<td>14</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': [0.18150728940963745], 'zero_point': [-117]}</td>
</tr>
<tr>
<td>14</td><td>wake_word/quant_dense_1/MatMul;wake_word/quant_dense_1/LastValueQuant/FakeQuantWithMinMaxVars</td>
<td>INT8</td>
<td>[32, 1760]</td>
<td>None</td>
<td>15</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': [0.006678517442196608], 'zero_point': [0]}</td>
</tr>
<tr>
<td>15</td><td>wake_word/quant_dense_1/MatMul;wake_word/quant_dense_1/Relu;wake_word/quant_dense_1/BiasAdd</td>
<td>INT8</td>
<td>[1, 32]</td>
<td>[-1, 32]</td>
<td>16</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': [0.4009203314781189], 'zero_point': [-123]}</td>
</tr>
<tr>
<td>16</td><td>wake_word/quant_output/MatMul;wake_word/quant_output/LastValueQuant/FakeQuantWithMinMaxVars</td>
<td>INT8</td>
<td>[1, 32]</td>
<td>None</td>
<td>17</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': [0.0030947132036089897], 'zero_point': [0]}</td>
</tr>
<tr>
<td>17</td><td>wake_word/quant_output/MatMul;wake_word/quant_output/BiasAdd</td>
<td>INT8</td>
<td>[1, 1]</td>
<td>[-1, 1]</td>
<td>18</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': [0.44968703389167786], 'zero_point': [44]}</td>
</tr>
<tr>
<td>18</td><td>wake_word/quant_output/Sigmoid</td>
<td>INT8</td>
<td>[1, 1]</td>
<td>[-1, 1]</td>
<td>19</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': [0.00390625], 'zero_point': [-128]}</td>
</tr>
<tr>
<td>19</td><td>StatefulPartitionedCall:0</td>
<td>FLOAT32</td>
<td>[1, 1]</td>
<td>[-1, 1]</td>
<td>20</td>
<td>{'details': None, 'details_type': 0, 'max': None, 'min': None, 'quantized_dimension': 0, 'scale': None, 'zero_point': None}</td>
</tr>
</table>
<h3>Ops</h3>
<table><tr>
<tr>
<th>index</th><th>inputs</th><th>outputs</th><th>builtin_options</th><th>opcode_index</th></tr>
<tr>
<td>0</td><td><span class='tooltip'><span class='tooltipcontent'>0 serving_default_conv2d_1_input:0 FLOAT32 [1, 99, 43, 1][-1, 99, 43, 1]<br></span>[0]</span></td>
<td><span class='tooltip'><span class='tooltipcontent'>6 wake_word/quantize_layer_2/AllValuesQuantize/FakeQuantWithMinMaxVars;wake_word/quantize_layer_2/AllValuesQuantize/FakeQuantWithMinMaxVars/ReadVariableOp;wake_word/quantize_layer_2/AllValuesQuantize/FakeQuantWithMinMaxVars/ReadVariableOp_1 INT8 [1, 99, 43, 1][-1, 99, 43, 1]<br></span>[6]</span></td>
<td>None</td>
<td>QUANTIZE (0)</td>
</tr>
<tr>
<td>1</td><td><span class='tooltip'><span class='tooltipcontent'>6 wake_word/quantize_layer_2/AllValuesQuantize/FakeQuantWithMinMaxVars;wake_word/quantize_layer_2/AllValuesQuantize/FakeQuantWithMinMaxVars/ReadVariableOp;wake_word/quantize_layer_2/AllValuesQuantize/FakeQuantWithMinMaxVars/ReadVariableOp_1 INT8 [1, 99, 43, 1][-1, 99, 43, 1]<br>7 wake_word/quant_conv2d_1/Conv2D;wake_word/quant_conv2d_1/LastValueQuant/FakeQuantWithMinMaxVarsPerChannel INT8 [32, 5, 5, 1]None<br>2 wake_word/quant_conv2d_1/BiasAdd/ReadVariableOp INT32 [32]None<br></span>[6, 7, 2]</span></td>
<td><span class='tooltip'><span class='tooltipcontent'>8 wake_word/quant_conv2d_1/Relu;wake_word/quant_conv2d_1/BiasAdd;wake_word/quant_conv2d_2/Conv2D;wake_word/quant_conv2d_1/Conv2D;wake_word/quant_conv2d_1/BiasAdd/ReadVariableOp INT8 [1, 99, 43, 32][-1, 99, 43, 32]<br></span>[8]</span></td>
<td>{'dilation_h_factor': 1, 'dilation_w_factor': 1, 'fused_activation_function': 1, 'padding': 0, 'stride_h': 1, 'stride_w': 1}</td>
<td>CONV_2D (1)</td>
</tr>
<tr>
<td>2</td><td><span class='tooltip'><span class='tooltipcontent'>8 wake_word/quant_conv2d_1/Relu;wake_word/quant_conv2d_1/BiasAdd;wake_word/quant_conv2d_2/Conv2D;wake_word/quant_conv2d_1/Conv2D;wake_word/quant_conv2d_1/BiasAdd/ReadVariableOp INT8 [1, 99, 43, 32][-1, 99, 43, 32]<br></span>[8]</span></td>
<td><span class='tooltip'><span class='tooltipcontent'>9 wake_word/quant_pool2d_1/MaxPool INT8 [1, 33, 15, 32][-1, 33, 15, 32]<br></span>[9]</span></td>
<td>{'filter_height': 3, 'filter_width': 3, 'fused_activation_function': 0, 'padding': 0, 'stride_h': 3, 'stride_w': 3}</td>
<td>MAX_POOL_2D (2)</td>
</tr>
<tr>
<td>3</td><td><span class='tooltip'><span class='tooltipcontent'>9 wake_word/quant_pool2d_1/MaxPool INT8 [1, 33, 15, 32][-1, 33, 15, 32]<br>10 wake_word/quant_conv2d_2/Conv2D;wake_word/quant_conv2d_2/LastValueQuant/FakeQuantWithMinMaxVarsPerChannel INT8 [32, 3, 3, 32]None<br>3 wake_word/quant_conv2d_2/BiasAdd/ReadVariableOp INT32 [32]None<br></span>[9, 10, 3]</span></td>
<td><span class='tooltip'><span class='tooltipcontent'>11 wake_word/quant_conv2d_2/Relu;wake_word/quant_conv2d_2/BiasAdd;wake_word/quant_conv2d_2/Conv2D;wake_word/quant_conv2d_2/BiasAdd/ReadVariableOp INT8 [1, 33, 15, 32][-1, 33, 15, 32]<br></span>[11]</span></td>
<td>{'dilation_h_factor': 1, 'dilation_w_factor': 1, 'fused_activation_function': 1, 'padding': 0, 'stride_h': 1, 'stride_w': 1}</td>
<td>CONV_2D (1)</td>
</tr>
<tr>
<td>4</td><td><span class='tooltip'><span class='tooltipcontent'>11 wake_word/quant_conv2d_2/Relu;wake_word/quant_conv2d_2/BiasAdd;wake_word/quant_conv2d_2/Conv2D;wake_word/quant_conv2d_2/BiasAdd/ReadVariableOp INT8 [1, 33, 15, 32][-1, 33, 15, 32]<br></span>[11]</span></td>
<td><span class='tooltip'><span class='tooltipcontent'>12 wake_word/quant_pool2d_2/MaxPool INT8 [1, 11, 5, 32][-1, 11, 5, 32]<br></span>[12]</span></td>
<td>{'filter_height': 3, 'filter_width': 3, 'fused_activation_function': 0, 'padding': 0, 'stride_h': 3, 'stride_w': 3}</td>
<td>MAX_POOL_2D (2)</td>
</tr>
<tr>
<td>5</td><td><span class='tooltip'><span class='tooltipcontent'>12 wake_word/quant_pool2d_2/MaxPool INT8 [1, 11, 5, 32][-1, 11, 5, 32]<br>1 wake_word/quant_flatten_5/Const INT32 [2]None<br></span>[12, 1]</span></td>
<td><span class='tooltip'><span class='tooltipcontent'>13 wake_word/quant_flatten_5/Reshape INT8 [1, 1760][-1, 1760]<br></span>[13]</span></td>
<td>None</td>
<td>RESHAPE (3)</td>
</tr>
<tr>
<td>6</td><td><span class='tooltip'><span class='tooltipcontent'>13 wake_word/quant_flatten_5/Reshape INT8 [1, 1760][-1, 1760]<br>14 wake_word/quant_dense_1/MatMul;wake_word/quant_dense_1/LastValueQuant/FakeQuantWithMinMaxVars INT8 [32, 1760]None<br>5 wake_word/quant_dense_1/BiasAdd/ReadVariableOp INT32 [32]None<br></span>[13, 14, 5]</span></td>
<td><span class='tooltip'><span class='tooltipcontent'>15 wake_word/quant_dense_1/MatMul;wake_word/quant_dense_1/Relu;wake_word/quant_dense_1/BiasAdd INT8 [1, 32][-1, 32]<br></span>[15]</span></td>
<td>{'asymmetric_quantize_inputs': False, 'fused_activation_function': 1, 'keep_num_dims': False, 'weights_format': 0}</td>
<td>FULLY_CONNECTED (4)</td>
</tr>
<tr>
<td>7</td><td><span class='tooltip'><span class='tooltipcontent'>15 wake_word/quant_dense_1/MatMul;wake_word/quant_dense_1/Relu;wake_word/quant_dense_1/BiasAdd INT8 [1, 32][-1, 32]<br>16 wake_word/quant_output/MatMul;wake_word/quant_output/LastValueQuant/FakeQuantWithMinMaxVars INT8 [1, 32]None<br>4 wake_word/quant_output/BiasAdd/ReadVariableOp INT32 [1]None<br></span>[15, 16, 4]</span></td>
<td><span class='tooltip'><span class='tooltipcontent'>17 wake_word/quant_output/MatMul;wake_word/quant_output/BiasAdd INT8 [1, 1][-1, 1]<br></span>[17]</span></td>
<td>{'asymmetric_quantize_inputs': False, 'fused_activation_function': 0, 'keep_num_dims': False, 'weights_format': 0}</td>
<td>FULLY_CONNECTED (4)</td>
</tr>
<tr>
<td>8</td><td><span class='tooltip'><span class='tooltipcontent'>17 wake_word/quant_output/MatMul;wake_word/quant_output/BiasAdd INT8 [1, 1][-1, 1]<br></span>[17]</span></td>
<td><span class='tooltip'><span class='tooltipcontent'>18 wake_word/quant_output/Sigmoid INT8 [1, 1][-1, 1]<br></span>[18]</span></td>
<td>None</td>
<td>LOGISTIC (5)</td>
</tr>
<tr>
<td>9</td><td><span class='tooltip'><span class='tooltipcontent'>18 wake_word/quant_output/Sigmoid INT8 [1, 1][-1, 1]<br></span>[18]</span></td>
<td><span class='tooltip'><span class='tooltipcontent'>19 StatefulPartitionedCall:0 FLOAT32 [1, 1][-1, 1]<br></span>[19]</span></td>
<td>None</td>
<td>DEQUANTIZE (6)</td>
</tr>
</table>
<svg id='subgraph0' width='1600' height='900'></svg>

  <script>
    function buildGraph() {
      // Build graph data
      var graph = {"nodes": [{"id": "o0", "name": "QUANTIZE (0)", "group": 2, "x": 200, "y": 200}, {"id": "o1", "name": "CONV_2D (1)", "group": 2, "x": 200, "y": 400}, {"id": "o2", "name": "MAX_POOL_2D (2)", "group": 2, "x": 200, "y": 600}, {"id": "o3", "name": "CONV_2D (1)", "group": 2, "x": 200, "y": 800}, {"id": "o4", "name": "MAX_POOL_2D (2)", "group": 2, "x": 200, "y": 1000}, {"id": "o5", "name": "RESHAPE (3)", "group": 2, "x": 200, "y": 1200}, {"id": "o6", "name": "FULLY_CONNECTED (4)", "group": 2, "x": 200, "y": 1400}, {"id": "o7", "name": "FULLY_CONNECTED (4)", "group": 2, "x": 200, "y": 1600}, {"id": "o8", "name": "LOGISTIC (5)", "group": 2, "x": 200, "y": 1800}, {"id": "o9", "name": "DEQUANTIZE (6)", "group": 2, "x": 200, "y": 2000}, {"id": "t0", "name": "[] (0)", "group": 1, "x": 170, "y": 100.0}, {"id": "t1", "name": "[] (1)", "group": 1, "x": 340, "y": 1100.0}, {"id": "t2", "name": "[] (2)", "group": 1, "x": 510, "y": 300.0}, {"id": "t3", "name": "[] (3)", "group": 1, "x": 510, "y": 700.0}, {"id": "t4", "name": "[] (4)", "group": 1, "x": 510, "y": 1500.0}, {"id": "t5", "name": "[] (5)", "group": 1, "x": 510, "y": 1300.0}, {"id": "t6", "name": "[] (6)", "group": 1, "x": 170, "y": 300.0}, {"id": "t7", "name": "[] (7)", "group": 1, "x": 340, "y": 300.0}, {"id": "t8", "name": "[] (8)", "group": 1, "x": 170, "y": 500.0}, {"id": "t9", "name": "[] (9)", "group": 1, "x": 170, "y": 700.0}, {"id": "t10", "name": "[] (10)", "group": 1, "x": 340, "y": 700.0}, {"id": "t11", "name": "[] (11)", "group": 1, "x": 170, "y": 900.0}, {"id": "t12", "name": "[] (12)", "group": 1, "x": 170, "y": 1100.0}, {"id": "t13", "name": "[] (13)", "group": 1, "x": 170, "y": 1300.0}, {"id": "t14", "name": "[] (14)", "group": 1, "x": 340, "y": 1300.0}, {"id": "t15", "name": "[] (15)", "group": 1, "x": 170, "y": 1500.0}, {"id": "t16", "name": "[] (16)", "group": 1, "x": 340, "y": 1500.0}, {"id": "t17", "name": "[] (17)", "group": 1, "x": 170, "y": 1700.0}, {"id": "t18", "name": "[] (18)", "group": 1, "x": 170, "y": 1900.0}, {"id": "t19", "name": "[] (19)", "group": 1, "x": 170, "y": 2100.0}], "edges": [{"source": "t0", "target": "o0"}, {"target": "t6", "source": "o0"}, {"source": "t6", "target": "o1"}, {"source": "t7", "target": "o1"}, {"source": "t2", "target": "o1"}, {"target": "t8", "source": "o1"}, {"source": "t8", "target": "o2"}, {"target": "t9", "source": "o2"}, {"source": "t9", "target": "o3"}, {"source": "t10", "target": "o3"}, {"source": "t3", "target": "o3"}, {"target": "t11", "source": "o3"}, {"source": "t11", "target": "o4"}, {"target": "t12", "source": "o4"}, {"source": "t12", "target": "o5"}, {"source": "t1", "target": "o5"}, {"target": "t13", "source": "o5"}, {"source": "t13", "target": "o6"}, {"source": "t14", "target": "o6"}, {"source": "t5", "target": "o6"}, {"target": "t15", "source": "o6"}, {"source": "t15", "target": "o7"}, {"source": "t16", "target": "o7"}, {"source": "t4", "target": "o7"}, {"target": "t17", "source": "o7"}, {"source": "t17", "target": "o8"}, {"target": "t18", "source": "o8"}, {"source": "t18", "target": "o9"}, {"target": "t19", "source": "o9"}]};

      var svg = d3.select("#subgraph0")
      var width = svg.attr("width");
      var height = svg.attr("height");
      // Make the graph scrollable.
      svg = svg.call(d3.zoom().on("zoom", function() {
        svg.attr("transform", d3.event.transform);
      })).append("g");


      var color = d3.scaleOrdinal(d3.schemeDark2);

      var simulation = d3.forceSimulation()
          .force("link", d3.forceLink().id(function(d) {return d.id;}))
          .force("charge", d3.forceManyBody())
          .force("center", d3.forceCenter(0.5 * width, 0.5 * height));

      var edge = svg.append("g").attr("class", "edges").selectAll("line")
        .data(graph.edges).enter().append("path").attr("stroke","black").attr("fill","none")

      // Make the node group
      var node = svg.selectAll(".nodes")
        .data(graph.nodes)
        .enter().append("g")
        .attr("x", function(d){return d.x})
        .attr("y", function(d){return d.y})
        .attr("transform", function(d) {
          return "translate( " + d.x + ", " + d.y + ")"
        })
        .attr("class", "nodes")
          .call(d3.drag()
              .on("start", function(d) {
                if(!d3.event.active) simulation.alphaTarget(1.0).restart();
                d.fx = d.x;d.fy = d.y;
              })
              .on("drag", function(d) {
                d.fx = d3.event.x; d.fy = d3.event.y;
              })
              .on("end", function(d) {
                if (!d3.event.active) simulation.alphaTarget(0);
                d.fx = d.fy = null;
              }));
      // Within the group, draw a box for the node position and text
      // on the side.

      var node_width = 150;
      var node_height = 30;

      node.append("rect")
          .attr("r", "5px")
          .attr("width", node_width)
          .attr("height", node_height)
          .attr("rx", function(d) { return d.group == 1 ? 1 : 10; })
          .attr("stroke", "#000000")
          .attr("fill", function(d) { return d.group == 1 ? "#dddddd" : "#000000"; })
      node.append("text")
          .text(function(d) { return d.name; })
          .attr("x", 5)
          .attr("y", 20)
          .attr("fill", function(d) { return d.group == 1 ? "#000000" : "#eeeeee"; })
      // Setup force parameters and update position callback


      var node = svg.selectAll(".nodes")
        .data(graph.nodes);

      // Bind the links
      var name_to_g = {}
      node.each(function(data, index, nodes) {
        console.log(data.id)
        name_to_g[data.id] = this;
      });

      function proc(w, t) {
        return parseInt(w.getAttribute(t));
      }
      edge.attr("d", function(d) {
        function lerp(t, a, b) {
          return (1.0-t) * a + t * b;
        }
        var x1 = proc(name_to_g[d.source],"x") + node_width /2;
        var y1 = proc(name_to_g[d.source],"y") + node_height;
        var x2 = proc(name_to_g[d.target],"x") + node_width /2;
        var y2 = proc(name_to_g[d.target],"y");
        var s = "M " + x1 + " " + y1
            + " C " + x1 + " " + lerp(.5, y1, y2)
            + " " + x2 + " " + lerp(.5, y1, y2)
            + " " + x2  + " " + y2
      return s;
    });

  }
  buildGraph()
</script>
</div><h2>Buffers</h2>
<table><tr>
<tr>
<th>index</th><th>data</th></tr>
<tr>
<td>0</td><td>--</td>
</tr>
<tr>
<td>1</td><td>--</td>
</tr>
<tr>
<td>2</td><td>8 bytes</td>
</tr>
<tr>
<td>3</td><td>128 bytes</td>
</tr>
<tr>
<td>4</td><td>128 bytes</td>
</tr>
<tr>
<td>5</td><td>4 bytes</td>
</tr>
<tr>
<td>6</td><td>128 bytes</td>
</tr>
<tr>
<td>7</td><td>--</td>
</tr>
<tr>
<td>8</td><td>800 bytes</td>
</tr>
<tr>
<td>9</td><td>--</td>
</tr>
<tr>
<td>10</td><td>--</td>
</tr>
<tr>
<td>11</td><td>9216 bytes</td>
</tr>
<tr>
<td>12</td><td>--</td>
</tr>
<tr>
<td>13</td><td>--</td>
</tr>
<tr>
<td>14</td><td>--</td>
</tr>
<tr>
<td>15</td><td>56320 bytes</td>
</tr>
<tr>
<td>16</td><td>--</td>
</tr>
<tr>
<td>17</td><td>32 bytes</td>
</tr>
<tr>
<td>18</td><td>--</td>
</tr>
<tr>
<td>19</td><td>--</td>
</tr>
<tr>
<td>20</td><td>--</td>
</tr>
<tr>
<td>21</td><td>16 bytes</td>
</tr>
<tr>
<td>22</td><td>88 bytes</td>
</tr>
</table>
<h2>Operator Codes</h2>
<table><tr>
<tr>
<th>index</th><th>builtin_code</th><th>custom_code</th><th>version</th></tr>
<tr>
<td>0</td><td>QUANTIZE</td>
<td></td>
<td>1</td>
</tr>
<tr>
<td>1</td><td>CONV_2D</td>
<td></td>
<td>3</td>
</tr>
<tr>
<td>2</td><td>MAX_POOL_2D</td>
<td></td>
<td>2</td>
</tr>
<tr>
<td>3</td><td>RESHAPE</td>
<td></td>
<td>1</td>
</tr>
<tr>
<td>4</td><td>FULLY_CONNECTED</td>
<td></td>
<td>4</td>
</tr>
<tr>
<td>5</td><td>LOGISTIC</td>
<td></td>
<td>2</td>
</tr>
<tr>
<td>6</td><td>DEQUANTIZE</td>
<td></td>
<td>2</td>
</tr>
</table>
</body></html>
