{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49b6e4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T22:57:21.680575Z",
     "start_time": "2023-05-24T22:57:19.456280Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# todo: clean up imports\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.python.ops import gen_audio_ops\n",
    "import python_speech_features\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import librosa as rosa\n",
    "\n",
    "from IPython.display import display, Audio, HTML\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(f'Tensorflow v{tf.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27685b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T22:57:21.685511Z",
     "start_time": "2023-05-24T22:57:21.681936Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join('.', 'data')\n",
    "words_dirs = [d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d)) and not d.startswith('_')]\n",
    "print(words_dirs)\n",
    "\n",
    "TARGET_WORD = 'komputer'\n",
    "TARGET_LABEL = 1.0\n",
    "NOT_TARGET_LABEL = 0.0\n",
    "\n",
    "OTHER_WORDS = list(filter(lambda w: w != TARGET_WORD, words_dirs))\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "WINDOW_SIZE = 320\n",
    "WINDOW_STEP = 160\n",
    "WINDOW_LENGTH_IN_MS = WINDOW_SIZE / SAMPLE_RATE\n",
    "WINDOW_STEP_IN_MS = WINDOW_STEP / SAMPLE_RATE\n",
    "\n",
    "VOICE_THRESHOLD = 0.15\n",
    "BG_VOLUME = 0.1\n",
    "POOLING_SIZE = [1, 4]\n",
    "\n",
    "NO_AUDIO_SHIFTS = 2\n",
    "NO_BG_MIXED = 1\n",
    "NO_FREQ_MASK_SPECS = 1\n",
    "NO_TIME_MASK_SPECS = 1\n",
    "MASK_MAX_WIDTH = 3\n",
    "\n",
    "DEBUG = False\n",
    "PLOT_SIZE = (10, 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2db6b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T22:57:21.690741Z",
     "start_time": "2023-05-24T22:57:21.686424Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_audio(audio, ax=None, desc=None):\n",
    "    if not DEBUG:\n",
    "        return\n",
    "\n",
    "    if desc is not None:\n",
    "        display(HTML(f'<h1><center>{desc}</center></h1>'))\n",
    "    \n",
    "    axe = ax\n",
    "    if ax is None:\n",
    "        _, axe = plt.subplots(figsize=PLOT_SIZE)\n",
    "\n",
    "    axe.plot(audio)\n",
    "    axe.set_title('Audio wave')\n",
    "    axe.set_xlabel('Time')\n",
    "    axe.set_ylabel('Amplitude')\n",
    "    \n",
    "    if ax is None:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_spec(spec, ax=None, desc=None):\n",
    "    if not DEBUG:\n",
    "        return\n",
    "\n",
    "    if desc is not None:\n",
    "        display(HTML(f'<h1><center>{desc}</center></h1>'))\n",
    "\n",
    "    axe = ax\n",
    "    if ax is None:\n",
    "        _, axe = plt.subplots(figsize=PLOT_SIZE)\n",
    "\n",
    "    spec = np.squeeze(spec)\n",
    "    im = axe.imshow(spec, aspect='auto', origin='lower', cmap='jet')\n",
    "    axe.figure.colorbar(im, ax=axe, label='Magnitude')\n",
    "    axe.set_title('Spectrogram')\n",
    "    axe.set_xlabel('Time')\n",
    "    axe.set_ylabel('Frequency')\n",
    "    \n",
    "    if ax is None:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def debug_audio(audio, desc='Audio', feature_type='spec'):\n",
    "    if not DEBUG:\n",
    "        return\n",
    "\n",
    "    display(HTML(f'<h1><center>{desc}</center></h1>'))\n",
    "    fig, axes = plt.subplots(1, 2, figsize=PLOT_SIZE)\n",
    "    \n",
    "    if feature_type == 'mfcc':\n",
    "        mfcc = get_mfcc(audio)\n",
    "        plot_mfcc(mfcc, ax=axes[1])\n",
    "    elif feature_type == 'spec':\n",
    "        spec = get_spectrogram(audio)\n",
    "        print(spec.shape)\n",
    "        plot_spec(spec, ax=axes[1])\n",
    "\n",
    "    plot_audio(audio, ax=axes[0])\n",
    "    display(Audio(audio, rate=SAMPLE_RATE))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c311dc2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T22:57:27.774150Z",
     "start_time": "2023-05-24T22:57:27.743026Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def begin_voice(audio):\n",
    "    \"\"\"\n",
    "        Move voice to the beginning of the recording.\n",
    "    \"\"\"\n",
    "    start, end = find_voice(audio)\n",
    "    start = max(0, start - 100)\n",
    "    end = min(SAMPLE_RATE, end + 100)\n",
    "    return cure_audio(audio[start:end])\n",
    "\n",
    "\n",
    "def find_voice(audio):\n",
    "    \"\"\"\n",
    "        Find voice start and end points in the audio.\n",
    "    \"\"\"\n",
    "\n",
    "    audio_abs = np.abs(audio)\n",
    "    start = np.argmax(audio_abs > VOICE_THRESHOLD)\n",
    "    end = len(audio_abs) - np.argmax(audio_abs[::-1] > VOICE_THRESHOLD) - 1\n",
    "    return start, end\n",
    "\n",
    "\n",
    "def time_stretch_audio(audios, r):\n",
    "    \"\"\"\n",
    "        Speed up or slow down provided audios by a given rate.\n",
    "    \"\"\"\n",
    "\n",
    "    res = []\n",
    "    for a in audios:\n",
    "        copy = rosa.effects.time_stretch(a, rate=r)\n",
    "        copy = cure_audio(copy)\n",
    "        res.append(copy)\n",
    "        debug_audio(copy, desc=f'Time stretched audio by rate {r}')\n",
    "    return res\n",
    "\n",
    "\n",
    "def pitch_shift_audio(audios, s):\n",
    "    \"\"\"\n",
    "        Shift pitch by the given number of half-tones in provided audios.\n",
    "    \"\"\"\n",
    "\n",
    "    res = []\n",
    "    for a in audios:\n",
    "        copy = rosa.effects.pitch_shift(a, sr=SAMPLE_RATE, n_steps=s)\n",
    "        copy = cure_audio(copy)\n",
    "        res.append(copy)\n",
    "        debug_audio(copy, desc=f'Pitch shifted audio by {s} half-tones')\n",
    "    return res\n",
    "\n",
    "\n",
    "def mix_audio(audios):\n",
    "    \"\"\"\n",
    "        Mix provided audios with background noise samples.\n",
    "    \"\"\"\n",
    "\n",
    "    res = []\n",
    "    for a in audios:\n",
    "        for i in range(NO_AUDIO_SHIFTS):\n",
    "            noise = bg_noises[random.randint(0, len(bg_noises) - 1)]\n",
    "            noise_start = random.randint(0, len(noise) - SAMPLE_RATE)\n",
    "            noise = noise[noise_start:noise_start + SAMPLE_RATE]\n",
    "            copy = a + noise\n",
    "            copy = cure_audio(copy)\n",
    "            res.append(copy)\n",
    "            debug_audio(copy, desc='Audio mixed with noise')\n",
    "    return res\n",
    "\n",
    "\n",
    "def shift_audio(audios):\n",
    "    \"\"\"\n",
    "        Shifts voice in provided audios.\n",
    "    \"\"\"\n",
    "\n",
    "    res = []\n",
    "    for a in audios:\n",
    "        start, end = find_voice(a)\n",
    "        silence_len = len(a) + start - end\n",
    "        silence_interval = silence_len // NO_AUDIO_SHIFTS\n",
    "        for i in range(NO_AUDIO_SHIFTS):\n",
    "            shift = (i + 1) * silence_interval\n",
    "            shift = shift - start if shift > start else -shift\n",
    "            copy = np.roll(a, shift)\n",
    "            copy = cure_audio(copy)\n",
    "            res.append(copy)\n",
    "            debug_audio(copy, desc=f'Audio shifted by {shift} samples')\n",
    "    return res\n",
    "\n",
    "\n",
    "def freq_mask(spec, value=None, width=MASK_MAX_WIDTH):\n",
    "    \"\"\"\n",
    "        Add the mean-value mask to the frequency dimension of the spectrogram.\n",
    "    \"\"\"\n",
    "\n",
    "    if value is None:\n",
    "        value = spec.mean()\n",
    "        \n",
    "    copy = spec.copy()\n",
    "    mel_channels = copy.shape[1]\n",
    "    w = random.randint(1, width)\n",
    "    f_start = random.randint(0, mel_channels - w)\n",
    "    f_end = random.randint(f_start + 1, f_start + w)\n",
    "    copy[:, f_start:f_end, :] = value\n",
    "    plot_spec(copy, desc='Frequency masked spectrogram')\n",
    "    return copy\n",
    "\n",
    "\n",
    "def time_mask(spec, value=None, width=MASK_MAX_WIDTH):\n",
    "    \"\"\"\n",
    "        Add the zero mask to the frequency dimension of the spectrogram.\n",
    "    \"\"\"\n",
    "\n",
    "    if value is None:\n",
    "        value = spec.mean()\n",
    "\n",
    "    copy = spec.copy()\n",
    "    time_channels = copy.shape[0]\n",
    "    w = random.randint(1, width)\n",
    "    t_start = random.randint(0, time_channels - w)\n",
    "    t_end = random.randint(t_start + 1, t_start + w)\n",
    "    copy[t_start:t_end, :, :] = value\n",
    "    plot_spec(copy, desc='Time masked spectrogram')\n",
    "    return copy\n",
    "\n",
    "\n",
    "def normalize_audio(audio):\n",
    "    \"\"\"\n",
    "        Normalize audio.\n",
    "    \"\"\"\n",
    "\n",
    "    audio = audio - np.mean(audio)\n",
    "    audio = audio / np.max(np.abs(audio))\n",
    "    return audio\n",
    "\n",
    "\n",
    "def cut_audio_length(audio, length=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "        Cut audio to SAMPLE_RATE length.\n",
    "    \"\"\"\n",
    "\n",
    "    audio_len = len(audio)\n",
    "    if audio_len < length:\n",
    "        audio = np.append(audio, np.zeros(length - audio_len))\n",
    "    audio = audio[:length]\n",
    "    return audio\n",
    "\n",
    "\n",
    "def cure_audio(audio):\n",
    "    \"\"\"\n",
    "        Make sure that audio's length is fixed to SAMPLE_RATE and normalize.\n",
    "    \"\"\"\n",
    "\n",
    "    audio = cut_audio_length(audio)\n",
    "    audio = normalize_audio(audio)\n",
    "    return np.array(audio)\n",
    "\n",
    "\n",
    "def get_spectrogram(audio):\n",
    "    \"\"\"\n",
    "        Generate a spectrogram for a given audio. Then apply pooling to reduce dimensions.\n",
    "    \"\"\"\n",
    "    \n",
    "    audio = cure_audio(audio)\n",
    "    audio = tf.expand_dims(audio, -1)\n",
    "    audio = tf.cast(audio[:], tf.float32)\n",
    "\n",
    "    spec = gen_audio_ops.audio_spectrogram(audio,\n",
    "                                           window_size=WINDOW_SIZE,\n",
    "                                           stride=WINDOW_STEP,\n",
    "                                           magnitude_squared=True).numpy()\n",
    "\n",
    "    spec = tf.expand_dims(spec, -1)\n",
    "    spec = tf.nn.pool(input=spec,\n",
    "                      window_shape=POOLING_SIZE,\n",
    "                      strides=POOLING_SIZE,\n",
    "                      pooling_type='AVG',\n",
    "                      padding='SAME')\n",
    "    spec = tf.squeeze(spec, axis=0)\n",
    "    spec = np.log(spec + np.finfo(float).eps)\n",
    "    return spec\n",
    "\n",
    "\n",
    "def process_file(file_path, repeats=1):\n",
    "    \"\"\"\n",
    "        Process a file sample by adding more filters to all the samples generated in previous steps.\n",
    "    \"\"\"\n",
    "\n",
    "    audio, _ = rosa.load(file_path, sr=SAMPLE_RATE, mono=True)\n",
    "    audio = cure_audio(audio)\n",
    "    debug_audio(audio, desc=f'Pure audio [{os.path.basename(file_path)}]')\n",
    "\n",
    "    all_samples = [audio]\n",
    "    stretched = []\n",
    "    pitched = []\n",
    "    \n",
    "    for r in [0.85, 0.9, 1.1, 1.15]:\n",
    "        stretched += time_stretch_audio([audio], r)\n",
    "    \n",
    "    for s in [-1.5, -1.2, 1.2, 1.5]:\n",
    "        pitched += pitch_shift_audio([audio], s)\n",
    "        \n",
    "    all_samples += stretched\n",
    "    all_samples += pitched\n",
    "    \n",
    "    for i in range(repeats):\n",
    "        shifted = shift_audio([audio])\n",
    "        all_samples += shifted\n",
    "\n",
    "        bg_mixxx = mix_audio([audio])\n",
    "        all_samples += bg_mixxx\n",
    "\n",
    "    specs = []\n",
    "    for s in all_samples:\n",
    "        spec = get_spectrogram(cure_audio(s))\n",
    "        specs.append(spec)\n",
    "\n",
    "        for i in range(repeats):\n",
    "            specs.append(freq_mask(spec))\n",
    "\n",
    "        for i in range(repeats):\n",
    "            specs.append(time_mask(spec))\n",
    "            \n",
    "    if DEBUG:\n",
    "        print(f'Generated {len(specs)} spectrograms!')\n",
    "\n",
    "    return specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6991c07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T22:57:28.869726Z",
     "start_time": "2023-05-24T22:57:28.866818Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spectrograms = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b96db5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T22:57:56.409580Z",
     "start_time": "2023-05-24T22:57:31.364552Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_paths = glob.glob('data/_bgnoise/*.wav')\n",
    "progress_bar = tqdm(total=len(file_paths), desc='_bgnoise')\n",
    "bg_noises = []\n",
    "no_specs = 0\n",
    "\n",
    "for file_name in file_paths:\n",
    "    audio, _ = rosa.load(file_name, sr=SAMPLE_RATE, mono=True)\n",
    "    audio = normalize_audio(audio)\n",
    "    for i in range(0, len(audio) - SAMPLE_RATE, SAMPLE_RATE):\n",
    "        no_specs += 1\n",
    "        spectrograms.append((get_spectrogram(audio[i:i+SAMPLE_RATE]), NOT_TARGET_LABEL))\n",
    "    audio = BG_VOLUME * audio\n",
    "    debug_audio(audio, desc=f'Background noise [{file_name}]')\n",
    "    bg_noises.append(audio)\n",
    "    progress_bar.update()\n",
    "        \n",
    "print(f'Created {no_specs} spectrograms for background noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76824388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T23:00:10.645395Z",
     "start_time": "2023-05-24T22:57:56.410882Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_paths = glob.glob('data/_talking/*.wav')\n",
    "progress_bar = tqdm(total=len(file_paths), desc='_talking')\n",
    "no_specs = 0\n",
    "\n",
    "for file_name in file_paths:\n",
    "    audio, _ = rosa.load(file_name, sr=SAMPLE_RATE, mono=True)\n",
    "    audio = normalize_audio(audio)\n",
    "    for i in range(0, len(audio) - SAMPLE_RATE, SAMPLE_RATE):\n",
    "        no_specs += 1\n",
    "        spectrograms.append((get_spectrogram(audio[i:i+SAMPLE_RATE]), NOT_TARGET_LABEL))\n",
    "    debug_audio(audio, desc=f'Talking noise [{file_name}]')\n",
    "    progress_bar.update()\n",
    "        \n",
    "print(f'Created {no_specs} spectrograms for talking noise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7258b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T23:00:31.993173Z",
     "start_time": "2023-05-24T23:00:10.646517Z"
    }
   },
   "outputs": [],
   "source": [
    "file_paths = glob.glob(f'data/{TARGET_WORD}/*.wav')\n",
    "progress_bar = tqdm(total=len(file_paths), desc=TARGET_WORD)\n",
    "no_specs = 0\n",
    "\n",
    "for file_name in file_paths:\n",
    "    for s in process_file(file_name, 2):\n",
    "        no_specs += 1\n",
    "        spectrograms.append((s, TARGET_LABEL))\n",
    "    progress_bar.update()\n",
    "        \n",
    "print(f'Created {no_specs} spectrograms for {TARGET_WORD}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15acf86e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T23:11:22.069363Z",
     "start_time": "2023-05-24T23:00:42.500524Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for word in OTHER_WORDS:\n",
    "    file_paths = glob.glob(f'data/{word}/*.wav')\n",
    "    progress_bar = tqdm(total=len(file_paths), desc=word) # total=330!\n",
    "    no_specs = 0\n",
    "\n",
    "    for file_name in file_paths[:330]:\n",
    "        for s in process_file(file_name, 1):\n",
    "            no_specs += 1\n",
    "            spectrograms.append((s, NOT_TARGET_LABEL))\n",
    "        progress_bar.update()\n",
    "#         no_specs += 1\n",
    "#         audio, _ = rosa.load(file_name, sr=SAMPLE_RATE, mono=True)\n",
    "#         audio = cure_audio(audio)\n",
    "#         debug_audio(audio, desc=f'Pure audio [{os.path.basename(file_name)}]')\n",
    "#         spectrograms.append((get_spectrogram(audio), NOT_TARGET_LABEL))\n",
    "#         debug_audio(audio, desc=f'Word {word} [{file_name}]')\n",
    "#         progress_bar.update()\n",
    "\n",
    "    print(f'Created {no_specs} spectrograms for {word}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3423155",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T23:11:47.298205Z",
     "start_time": "2023-05-24T23:11:47.053269Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(spectrograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d102a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T23:11:51.254104Z",
     "start_time": "2023-05-24T23:11:50.617333Z"
    }
   },
   "outputs": [],
   "source": [
    "specs, labels = zip(*spectrograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db65487b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T23:14:38.571430Z",
     "start_time": "2023-05-24T23:11:51.255391Z"
    }
   },
   "outputs": [],
   "source": [
    "specs = np.array(specs)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd4520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T23:14:38.615041Z",
     "start_time": "2023-05-24T23:14:38.590151Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "no_specs = len(specs)\n",
    "train_end = int(no_specs * 0.6)\n",
    "val_end = int(no_specs * 0.8)\n",
    "\n",
    "ds_x = np.array_split(specs, [train_end, val_end])\n",
    "ds_y = np.array_split(labels, [train_end, val_end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c00565",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-24T23:23:04.650597Z",
     "start_time": "2023-05-24T23:14:38.616988Z"
    }
   },
   "outputs": [],
   "source": [
    "# todo: add id to the data to identify the sample after training to egzamine failures\n",
    "\n",
    "np.savez_compressed('train.npz', x=ds_x[0], y=ds_y[0])\n",
    "np.savez_compressed('val.npz', x=ds_x[1], y=ds_y[1])\n",
    "np.savez_compressed('test.npz', x=ds_x[2], y=ds_y[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b947d58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
